{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Recurrent Neural networks -Deep Neuron AI </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/rnn.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.layers.recurrent.SimpleRNN(units, activation='tanh', use_bias=True, \n",
    "                                 kernel_initializer='glorot_uniform', \n",
    "                                 recurrent_initializer='orthogonal', \n",
    "                                 bias_initializer='zeros', \n",
    "                                 kernel_regularizer=None, \n",
    "                                 recurrent_regularizer=None, \n",
    "                                 bias_regularizer=None, \n",
    "                                 activity_regularizer=None, \n",
    "                                 kernel_constraint=None, recurrent_constraint=None, \n",
    "                                 bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments:\n",
    "\n",
    "<ul>\n",
    "<li><strong>units</strong>: Positive integer, dimensionality of the output space.</li>\n",
    "<li><strong>activation</strong>: Activation function to use\n",
    "    (see <a href=\"http://keras.io/activations/\">activations</a>).\n",
    "    If you pass None, no activation is applied\n",
    "    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>\n",
    "<li><strong>use_bias</strong>: Boolean, whether the layer uses a bias vector.</li>\n",
    "<li><strong>kernel_initializer</strong>: Initializer for the <code>kernel</code> weights matrix,\n",
    "    used for the linear transformation of the inputs.\n",
    "    (see <a href=\"https://keras.io/initializers/\">initializers</a>).</li>\n",
    "<li><strong>recurrent_initializer</strong>: Initializer for the <code>recurrent_kernel</code>\n",
    "    weights matrix,\n",
    "    used for the linear transformation of the recurrent state.\n",
    "    (see <a href=\"https://keras.io/initializers/\">initializers</a>).</li>\n",
    "<li><strong>bias_initializer</strong>: Initializer for the bias vector\n",
    "    (see <a href=\"https://keras.io/initializers/\">initializers</a>).</li>\n",
    "<li><strong>kernel_regularizer</strong>: Regularizer function applied to\n",
    "    the <code>kernel</code> weights matrix\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>recurrent_regularizer</strong>: Regularizer function applied to\n",
    "    the <code>recurrent_kernel</code> weights matrix\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>bias_regularizer</strong>: Regularizer function applied to the bias vector\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>activity_regularizer</strong>: Regularizer function applied to\n",
    "    the output of the layer (its \"activation\").\n",
    "    (see <a href=\"https://keras.io/regularizers/\">regularizer</a>).</li>\n",
    "<li><strong>kernel_constraint</strong>: Constraint function applied to\n",
    "    the <code>kernel</code> weights matrix\n",
    "    (see <a href=\"https://keras.io/constraints/\">constraints</a>).</li>\n",
    "<li><strong>recurrent_constraint</strong>: Constraint function applied to\n",
    "    the <code>recurrent_kernel</code> weights matrix\n",
    "    (see <a href=\"https://keras.io/constraints/\">constraints</a>).</li>\n",
    "<li><strong>bias_constraint</strong>: Constraint function applied to the bias vector\n",
    "    (see <a href=\"https://keras.io/constraints/\">constraints</a>).</li>\n",
    "<li><strong>dropout</strong>: Float between 0 and 1.\n",
    "    Fraction of the units to drop for\n",
    "    the linear transformation of the inputs.</li>\n",
    "<li><strong>recurrent_dropout</strong>: Float between 0 and 1.\n",
    "    Fraction of the units to drop for\n",
    "    the linear transformation of the recurrent state.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backprop Through time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrary to feed-forward neural networks, the RNN is characterized by the ability of encoding longer past information, thus very suitable for sequential models. The BPTT extends the ordinary BP algorithm to suit the recurrent neural\n",
    "architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/rnn2.png\" width=\"45%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**: [Backpropagation through Time](http://ir.hit.edu.cn/~jguo/docs/notes/bptt.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import keras \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# -- Keras Import\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN\n",
    "\n",
    "from tensorflow.keras.layers import Activation, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB sentiment classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. \n",
    "\n",
    "IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. \n",
    "\n",
    "There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. \n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation - IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Example:\n",
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])]\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 100)\n",
      "X_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Example:')\n",
    "print(X_train[:1])\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, dtype='float32')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 15:44:03.176925: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 25s 32ms/step - loss: 0.7200 - val_loss: 0.6751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bcb2b10d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(SimpleRNN(128))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=1, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LSTM network is an artificial neural network that contains LSTM blocks instead of, or in addition to, regular network units. A LSTM block may be described as a \"smart\" network unit that can remember a value for an arbitrary length of time. \n",
    "\n",
    "Unlike traditional RNNs, an Long short-term memory network is well-suited to learn from experience to classify, process and predict time series when there are very long time lags of unknown size between important events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../imgs/gru.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.layers.recurrent.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "                            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
    "                            recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n",
    "                            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                            dropout=0.0, recurrent_dropout=0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments\n",
    "\n",
    "<ul>\n",
    "<li><strong>units</strong>: Positive integer, dimensionality of the output space.</li>\n",
    "<li><strong>activation</strong>: Activation function to use\n",
    "    If you pass None, no activation is applied\n",
    "    (ie. \"linear\" activation: <code>a(x) = x</code>).</li>\n",
    "<li><strong>recurrent_activation</strong>: Activation function to use\n",
    "    for the recurrent step.</li>\n",
    "<li><strong>use_bias</strong>: Boolean, whether the layer uses a bias vector.</li>\n",
    "<li><strong>kernel_initializer</strong>: Initializer for the <code>kernel</code> weights matrix,\n",
    "    used for the linear transformation of the inputs.</li>\n",
    "<li><strong>recurrent_initializer</strong>: Initializer for the <code>recurrent_kernel</code>\n",
    "    weights matrix,\n",
    "    used for the linear transformation of the recurrent state.</li>\n",
    "<li><strong>bias_initializer</strong>: Initializer for the bias vector.</li>\n",
    "<li><strong>unit_forget_bias</strong>: Boolean.\n",
    "    If True, add 1 to the bias of the forget gate at initialization.\n",
    "    Setting it to true will also force <code>bias_initializer=\"zeros\"</code>.\n",
    "    This is recommended in <a href=\"http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf\">Jozefowicz et al.</a></li>\n",
    "<li><strong>kernel_regularizer</strong>: Regularizer function applied to\n",
    "    the <code>kernel</code> weights matrix.</li>\n",
    "<li><strong>recurrent_regularizer</strong>: Regularizer function applied to\n",
    "    the <code>recurrent_kernel</code> weights matrix.</li>\n",
    "<li><strong>bias_regularizer</strong>: Regularizer function applied to the bias vector.</li>\n",
    "<li><strong>activity_regularizer</strong>: Regularizer function applied to\n",
    "    the output of the layer (its \"activation\").</li>\n",
    "<li><strong>kernel_constraint</strong>: Constraint function applied to\n",
    "    the <code>kernel</code> weights matrix.</li>\n",
    "<li><strong>recurrent_constraint</strong>: Constraint function applied to\n",
    "    the <code>recurrent_kernel</code> weights matrix.</li>\n",
    "<li><strong>bias_constraint</strong>: Constraint function applied to the bias vector.</li>\n",
    "<li><strong>dropout</strong>: Float between 0 and 1.\n",
    "    Fraction of the units to drop for\n",
    "    the linear transformation of the inputs.</li>\n",
    "<li><strong>recurrent_dropout</strong>: Float between 0 and 1.\n",
    "    Fraction of the units to drop for\n",
    "    the linear transformation of the recurrent state.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gated recurrent units are a gating mechanism in recurrent neural networks. \n",
    "\n",
    "Much similar to the LSTMs, they have fewer parameters than LSTM, as they lack an output gate.\n",
    "\n",
    "<img src=\"../imgs/gru.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.layers.recurrent.GRU(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n",
    "                           kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
    "                           bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, \n",
    "                           bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "                           recurrent_constraint=None, bias_constraint=None, \n",
    "                           dropout=0.0, recurrent_dropout=0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn! - Hands on Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/4\n",
      "782/782 [==============================] - 25s 31ms/step - loss: 0.7204 - val_loss: 0.6473\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 23s 30ms/step - loss: 0.5403 - val_loss: 0.6475\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 24s 31ms/step - loss: 0.5014 - val_loss: 0.5025\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 24s 31ms/step - loss: 0.3957 - val_loss: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb402d610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "\n",
    "# !!! Play with those! try and get better results!\n",
    "model.add(SimpleRNN(128))  \n",
    "#model.add(GRU(128))  \n",
    "#model.add(LSTM(128))  \n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, \n",
    "          epochs=4, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4962\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cx/0d815609101d3nf1_csjgkgm0000gn/T/ipykernel_1734/1949938155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional LSTM\n",
    "\n",
    "> This section demonstrates the use of a **Convolutional LSTM network**.\n",
    "\n",
    "> This network is used to predict the next frame of an artificially\n",
    "generated movie which contains moving squares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate movies with `3` to `7` moving squares inside.\n",
    "\n",
    "The squares are of shape $1 \\times 1$ or $2 \\times 2$ pixels, which move linearly over time.\n",
    "\n",
    "For convenience we first create movies with bigger width and height (`80x80`) \n",
    "and at the end we select a $40 \\times 40$ window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Data Generation\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a layer which take as input movies of shape `(n_frames, width, height, channels)` and returns a movie\n",
    "of identical shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network\n",
    "\n",
    "#### Beware: This takes time (~3 mins per epoch on my hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n",
      "/opt/anaconda3/envs/ds/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "95/95 [==============================] - 582s 6s/step - loss: 0.7789 - val_loss: 0.6932\n",
      "Epoch 2/3\n",
      "95/95 [==============================] - 1943s 21s/step - loss: 0.7404 - val_loss: 0.6707\n",
      "Epoch 3/3\n",
      "95/95 [==============================] - 584s 6s/step - loss: 0.7102 - val_loss: 0.6242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a6ff73fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        epochs=3, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 861ms/step\n",
      "1/1 [==============================] - 1s 710ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n"
     ]
    }
   ],
   "source": [
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../imgs/convlstm/1_animate.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cx/0d815609101d3nf1_csjgkgm0000gn/T/ipykernel_1734/1247993748.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../imgs/convlstm/%i_animate.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m                         ax.patch._cm_set(facecolor='none', edgecolor='none'))\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2326\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 **kwargs)\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mDECORATORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    541\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    542\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ds/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../imgs/convlstm/1_animate.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Inital trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig('../imgs/convlstm/%i_animate.png' % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
